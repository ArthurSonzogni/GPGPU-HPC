%------------------------------------------------------------------------------%
%                                                                              %
%                                                                              %
%   EnsiRapport Template                                                       %
%                                                                              %
%   Version : 1.0                                                              %
%                                                                              %
%   Auteur : Arthur Sonzogni                                                   %
%                                                                              %
%------------------------------------------------------------------------------%



\documentclass[liens,entete-ensimag,margeCorrection]{ensirapport}
% options possibles:
% -  ('10pt', '11pt' and '12pt') taille de police.
% -  ('a4paper', 'letterpaper', 'a5paper', 'legalpaper', 'executivepaper' and 'landscape') taille de papier.
% -  ('sans' and 'roman') famille de police.
% -- ('liens') ajoute les liens dans le sommaire.
% -- ('entete,entete-ensimag') ajoute des belles entetes avec logo ensimag ou pas.
% -- ('margeCorrection') diminue les enormes marges de latex.
% -- ('minted') inclus minted pour colorer les codes sources, ne fonctionne pas à l'ensimag.
% -  ('onecolumn','twocolumn') une ou deux colonnes
% -  ('fleqn','leqno') formules mathématique alignées a gauche ou a droite.
% -  ('notitlepage','titlepage') sans ou avec page de garde pour le titre

%\usepackage[draft]{graphicx}
\usepackage[nottoc, notlof, notlot]{tocbibind}
\setlength{\parindent}{0cm} % Défini la largeur de l'alinéa de 1cm.



\begin{document}


\title{Mon titre}
\author{Arthur Sonzogni}
\date{\today}

\renewcommand{\labelitemi}{\textbullet}

\large
\thispagestyle{plain}

\begin{center}


Institut National Polytechnique de Grenoble

École Nationale Supérieure d'Informatique et de Mathématiques Appliquées de
Grenoble

\vspace{0.4cm}


{\huge \bfseries HPC \& GPGPU}

\vspace{0.5cm}
{\large \bfseries Rapport des travaux}


\vspace{1.5cm}

\hrule width \textwidth height 2pt
\vspace{0.4cm}
{\Huge \bfseries HPC \& GPGPU.}
\vspace{0.4cm}
\hrule width \textwidth height 2pt

\vspace{2cm}

\end{center}
\begin{minipage}{0.5\textwidth}
    
{\it Auteurs:}

Arthur SONZOGNI
Thomas Coeffic

3A Grenoble INP - Ensimag

Filière MMIS (Modélisation Mathématique, Images, Simulation)

\end{minipage}


\vspace{2cm}

\begin{center}
Grenoble, le \today
\end{center}

\newpage
\normalsize

%\maketitle
\tableofcontents

\section{Aide mémoire}

\paragraph{Séquential}

\paragraph{OpenMP\_Simple}
\paragraph{OpenMP\_GRID ???}

\paragraph{GPGPU\_simple} partitionement par agents

\paragraph{HPC\_MPI} partitionement par agents
\paragraph{HPC\_MPI\_GRID} partitionement par espace



\section{Présentation des différents algorithmes}
\subsection{Algorithme séquentiel}


\subsection{Parallèlisation par agents (OpenMP)}
Le boucle principale parcours chaques agents pour déterminer sont incrément de vitesse.
L'algorithme se contente simplement de parallèliser cette boucle.

\subsection{Parallèlisation par agents (MPI)}
Ici encore, on parallélise la boucle parcourant chaques agents.
Chaques processus à en charge une certaine proportion des boids.
Pour effectuer ces calculs il a besoin des positions et vitesse des boids géré par les autres processus.
Pour ce faire, après chaque tours, chaques processus effectue un envoie multicast de l'ensemble des boids dont il à la charge.

\begin{align*}
    \text{Travail par processeur} &: O\left( \frac n p \times n \right)  \\
    \text{Echange par processeur} &: O\left(n\right)
\end{align*}

Ainsi si $n \sim p$

\begin{align*}
    \text{Travail par processeur} &: O\left( n \right)  \\
    \text{Echange par processeur} &: O\left(n\right)
\end{align*}

\subsection{Parallèlisation par agents (CUDA)}

On effectue le même principe mais en utilisant la carte graphique.

\begin{align*}
    \text{Travail par cuda thread} &: O\left( \frac n p \times n \right)  \\
    \text{Accès mémoire globale} &: O\left(n\right)
\end{align*}

Ainsi si $n \sim p$

\begin{align*}
    \text{Travail par cuda thread} &: O\left( n \right)  \\
    \text{Accès mémoire globale} &: O\left(n\right)
\end{align*}

\subsection{Parallèlisation spatiale (Grille régulière) (MPI)}

Pour cet algorithme, au lieu de subdiviser par rapport aux agents, on subdivise l'espace en une grille régulière de $n^3$ blocks.
On effectue les calculs des dépendances entre boids qui sont dans le même blocs.
On approxime l'influence des boids des blocs voisins comme la présence d'un gros boids virtuel de position et de vitesse représentant la moyennes du block
et de poids la somme des poids du bloc.

Une étape de l'algorithme se résume à :
\begin{itemize}
    \item Calcul du boids virtuel
    \item Envoie et réception des boids virtuel des voisins.
    \item Calcul de la nouvelle position et vitesse (influence des boids du bloc et des 6 boids virtuels voisins).
    \item Calcul des boids sortant.
    \item Envoie des boids sortant vers les blocs voinsin et réception des boids entrant.
\end{itemize}

Pour le calcul des complexité, on fera l'hypothèse que le nombre de boids par bloc reste suffisament constant.
Cette dernière n'est pas vraiment respecté en pratique et on peut voir des ralentissement lorsque qu'un trop gros groupe de boids se forme.

\begin{align*}
    \text{Travail par processeur} &: O\left( \left(\frac np \right)^2 \right)  \\
    \text{Echange par processeur} &: O\left( \left(\frac np \right)^2 \right)
\end{align*}

Ainsi si $n \sim p$

\begin{align*}
    \text{Travail par processeur} &: O\left( 1 \right)  \\
    \text{Echange par processeur} &: O\left( 1 \right)
\end{align*}

On a donc un système qui passe très bien à l'échelle. On ne communique qu'avec les 6 blocks voisin.
Le principale défaut est qu'on utilise l'approximation du boids virtuel. La simulation est très rapidement différente que pour la simulation séquentiel, néanmoins, le comportement global est bien le même.

\subsection{Parallèlisation spatiale (Grille régulière) (CUDA)}
On effectue le même principe mais en utilisant la carte graphique.

\begin{align*}
    \text{Travail par cuda thread} &: O\left( \frac n p \times rc^2 \times n \right)  \\
    \text{Accès mémoire globale par thread} &: O\left( \frac n p \times rc^2 \times n \right)
\end{align*}

Ainsi si $n \sim p$

\begin{align*}
    \text{Travail par cuda thread} &: O\left( rc^2 \times n \right)  \\
    \text{Accès mémoire globale} &: O\left( rc^2 \times n \right)
\end{align*}

\end{document}
